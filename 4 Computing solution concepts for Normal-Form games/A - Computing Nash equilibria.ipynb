{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2156cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import linprog"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbe8279",
   "metadata": {},
   "source": [
    "# 4. Computing Solution Concepts of Normal-form games\n",
    "\n",
    "This chapter deals with the algorithms to compute things like equilibria, domination, etc. It starts with the easiest one, which is the zero-sum game:\n",
    "\n",
    "## 4.1 Computing Nash equilibria of two-player, zero-sum games\n",
    "\n",
    "In the previous chapter the idea of a minmax and maxmin solution was introduced. In a zero sum 2-player game it was noted that at equilibrium each player receives their minmax / maxmin value. We can use this to calculate the equilibrium by linear programming. \n",
    "\n",
    "Minmax means that the agent makes their best decision, given the other player will then minimise their return. Say I am player 1 and my best action is $A_1^j$. Then player 2 minimises my return by finding a mixed strategy $s_2$, to minimise:\n",
    "\n",
    "$$\\sum_{k} u_1(A_1^j,A_2^k)s_2^k$$\n",
    "\n",
    "Note: Here $k$ is the index of each action player 2 could take.\n",
    "\n",
    "This can be re-written in linear-programming style as:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\text{minimise} \\quad & U_1 \\\\\n",
    "\\text{subject to} \\quad & \\sum_{k} u_1(A_1^j,A_2^k)s_2^k \\leq U_1 \\\\\n",
    "\\text{} \\quad & \\sum_{k} s_2^k=1 \\\\\n",
    "\\text{} \\quad & s_2^k\\geq 0 \\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "(Why? Well, $\\min f(x)$ is the same as $\\min y$ subject to $f(x)\\leq y$.\n",
    "\n",
    "Of course, we don't actually know which action $j$ is the best for player 1, so we need to check every one:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\text{minimise} \\quad & U_1 \\\\\n",
    "\\text{subject to} \\quad & \\sum_{k} u_1(A_1^j,A_2^k)s_2^k \\leq U_1 \\quad \\forall A_1^j \\\\\n",
    "\\text{} \\quad & \\sum_{k} s_2^k=1 \\\\\n",
    "\\text{} \\quad & s_2^k\\geq 0 \\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Consider the Matching Pennies problem again:\n",
    "\n",
    "$\n",
    "\\begin{array}{c|cc}\n",
    "\\text{} & \\text{H} & \\text{T} \\\\\n",
    "\\hline\n",
    "\\text{H} & 1,-1 & -1,1 \\\\\n",
    "\\text{T} & -1,1 & 1,-1 \\\\\n",
    "\\end{array}\n",
    "$\n",
    "\n",
    "Written using the above strategy for player 1 this gives (here $s_2^1$ being the chance of player 2 going heads, $s_2^2$ their chance of tails):\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\text{minimise} \\quad & U_1 \\\\\n",
    "\\text{subject to} \\quad & s_2^1 - s_2^2 \\leq U_1 \\quad \\text{(player 1 goes heads)} \\\\\n",
    "\\text{} \\quad & -s_2^1+s_2^2 \\leq U_1 \\quad \\text{(player 1 goes tails)} \\\\\n",
    "\\text{} \\quad & s_2^1 + s_2^2=1 \\\\\n",
    "\\text{} \\quad & s_2 \\geq 0 \\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "The answer here is that $s_2^1=s_2^2=\\frac{1}{2}$. \n",
    "\n",
    "Here is an example for the more complicated game paper/scissors/rock. Note that scipy does $\\min c\\cdot x$, subject to $A\\cdot x \\geq b$, so the signs are flipped here in the function call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "751ce442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Player 2 strategy at equilibrium: [0.33 0.33 0.33]\n",
      "Player 1 utility: 0.0\n"
     ]
    }
   ],
   "source": [
    "c = np.array([0,0,0,1])\n",
    "A_ub = np.array([\n",
    "    [0,-1,1,-1], # PAPER. If player 2 now goes paper player 1 gets 0, -1 if scissors, 1 if rock.\n",
    "    [1,0,-1,-1], # SCISSORS. Note, as above the -1 at the end is because a+b+c<d is turned into a+b+c-d<0\n",
    "    [-1,1,0,-1], # ROCK.\n",
    "])\n",
    "b_ub = np.array([0,0,0])\n",
    "A_eq = np.array([[1,1,1,0]])\n",
    "b_eq = np.array([1])\n",
    "res = linprog(c, A_ub=-A_ub, b_ub=-b_ub, A_eq=A_eq, b_eq=b_eq, )\n",
    "print(\"Player 2 strategy at equilibrium:\",res[\"x\"].round(2)[:3])\n",
    "print(\"Player 1 utility:\",res[\"x\"].round(2)[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f37738",
   "metadata": {},
   "source": [
    "There we go. Unsuprisingly, the utility is 0 and the best option is to be random. \n",
    "\n",
    "We can also work out the strategy for player 1. One option is to do the above again in reverse. Another is to do maxmin instead, which corresponds to the dual problem:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\text{maximise} \\quad & U_1 \\\\\n",
    "\\text{subject to} \\quad & \\sum_{k} u_1(A_1^j,A_2^k)s_1^j \\leq U_1 \\quad \\forall A_2^k \\\\\n",
    "\\text{} \\quad & \\sum_{j} s_1^j=1 \\\\\n",
    "\\text{} \\quad & s_1^j\\geq 0 \\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "As a final note it can be useful to reformulate the equations from before (or the ones right above) by adding slack variables and turning the inequalities into equalities:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\text{minimise} \\quad & U_1 \\\\\n",
    "\\text{subject to} \\quad & \\sum_{k} u_1(A_1^j,A_2^k)s_2^k + r_1^j = U_1 \\quad \\forall A_1^j \\\\\n",
    "\\text{} \\quad & \\sum_{k} s_2^k=1 \\\\\n",
    "\\text{} \\quad & s_2^k\\geq 0 \\\\\n",
    "\\text{} \\quad & r_1^j\\geq 0 \\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "### 4.1.1 Note on 2-action games\n",
    "\n",
    "While the next section will show it is complicated to calculate equilibria in general two-player games, it is thankfully somewhat simple if there is only one action each.\n",
    "\n",
    "Consider the table:\n",
    "\n",
    "$\n",
    "\\begin{array}{c|cc}\n",
    "\\text{} & \\text{A} & \\text{B} \\\\\n",
    "\\hline\n",
    "\\text{A} & x_{11},y_{11} & x_{12},y_{12} \\\\\n",
    "\\text{B} & x_{21},y_{21} & x_{22},y_{22} \\\\\n",
    "\\end{array}\n",
    "$\n",
    "\n",
    "Say the probability of $A$ is $s_1$ and $s_2$ respectively. Then the benefit player 1 expects is:\n",
    "\n",
    "$$x_{11}s_1s_2+x_{12}s_1(1-s_2)+x_{21}(1-s_1)s_2+x_{22}(1-s_1)(1-s_2)$$\n",
    "\n",
    "Which can be expanded as:\n",
    "\n",
    "$$x_{11}s_1s_2+x_{12}s_1-x_{12}s_1s_2+x_{21}s_2-x_{21}s_1s_2+x_{22}-x_{22}s_2-x_{22}s_1+x_{22}s_1s_2$$\n",
    "\n",
    "Collecting the $s_1$ term:\n",
    "\n",
    "$$s_1(x_{11}s_2+x_{12}-x_{12}s_2-x_{21}s_2-x_{22}+x_{22}s_2)+x_{21}s_2+x_{22}-x_{22}s_2$$\n",
    "\n",
    "In order for player 1 to be indifferent between their actions we need to set the contents of the bracket to 0:\n",
    "\n",
    "$$x_{11}s_2+x_{12}-x_{12}s_2-x_{21}s_2-x_{22}+x_{22}s_2=0$$\n",
    "\n",
    "Solving for $s_2$:\n",
    "\n",
    "$$s_2=\\frac{x_{22}-x_{12}}{x_{11}-x_{12}-x_{21}+x_{22}}$$\n",
    "\n",
    "We can see this in an example game, e.g., the Battle of the Sexes:\n",
    "\n",
    "$\n",
    "\\begin{array}{c|cc}\n",
    "\\text{} & \\text{A} & \\text{B} \\\\\n",
    "\\hline\n",
    "\\text{A} & 2,1 & 0,0 \\\\\n",
    "\\text{B} & 0,0 & 1,2 \\\\\n",
    "\\end{array}\n",
    "$\n",
    "\n",
    "Here the value for player 2 is $\\frac{1-0}{2-0-0+1}=\\frac{1}{3}$, as expected.\n",
    "\n",
    "For player 1 the formula is exactly the same, but with $y$ instead of $x$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9722dd72",
   "metadata": {},
   "source": [
    "## 4.2 Computing Nash equilibria in general two-player games\n",
    "\n",
    "### 4.2.1 Complexity\n",
    "\n",
    "Unfortunately, computing Nash equilibria is a computationally challenging problem. It can be shown that it belongs to a class called PPAD, which it is believed grows exponentially.\n",
    "\n",
    "### 4.2.2 An LCP formulation and the Lemke-Howson algorithm\n",
    "\n",
    "#### The LCP formulation\n",
    "\n",
    "Although the problem of finding a Nash equilibrium in a general two player game can't be encoded as a linear program, it can be encoded as a linear complementarity problem (LCP). We do this as follows. We note that at equilibrium if agent 2 has strategy $s_2$ then any actions with a non-zero probability in $s_1$ are equally good, and therefore must give $U_1$, the optimal value:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\text{} \\quad & \\sum_{k} u_1(A_1^j,A_2^k)s_2^k = U_1 \\quad \\forall A_1^j|s_1^j>0 \\\\\n",
    "\\text{} \\quad & \\sum_{j} u_2(A_1^j,A_2^k)s_1^j = U_2 \\quad \\forall A_2^k|s_2^k>0 \\\\\n",
    "\\text{} \\quad & \\sum_{k} s_2^k=1 \\\\\n",
    "\\text{} \\quad & \\sum_{j} s_1^j=1 \\\\\n",
    "\\text{} \\quad & s_2^k\\geq 0 \\\\\n",
    "\\text{} \\quad & s_1^j\\geq 0 \\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "In order to convert this to a simpler linear format we introduce slack variables, similarly to above:\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\text{} \\quad & \\sum_{k} u_1(A_1^j,A_2^k)s_2^k + r_1^j = U_1 \\quad \\forall A_1^j \\\\\n",
    "\\text{} \\quad & \\sum_{j} u_2(A_1^j,A_2^k)s_1^j + r_2^k = U_2 \\quad \\forall A_2^k \\\\\n",
    "\\text{} \\quad & \\sum_{k} s_2^k=1 \\\\\n",
    "\\text{} \\quad & \\sum_{j} s_1^j=1 \\\\\n",
    "\\text{} \\quad & s_2^k\\geq 0 \\\\\n",
    "\\text{} \\quad & s_1^j\\geq 0 \\\\\n",
    "\\text{} \\quad & r_1^j\\geq 0 \\\\\n",
    "\\text{} \\quad & r_2^k\\geq 0 \\\\\n",
    "\\text{} \\quad & r_1^j\\cdot s_1^j = 0 \\\\\n",
    "\\text{} \\quad & r_2^k\\cdot s_2^k = 0 \\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "The last two equations state that if an action is included in the strategy, then the strategy at equilibrium must give the maximum utility. In other words, if an action $A_1^j$ is NOT in the solution, then when you take that action there is some gap $r_1^j$ to close in order to get to $U_1$. In an equilibrium strategy the agent is indifferent between the actions they do, so for any action in the solution it must give the optimal utilty.\n",
    "\n",
    "We can see this using the prisoners dilemma equilibrium as an example.\n",
    "\n",
    "$\n",
    "\\begin{array}{c|cc}\n",
    "\\text{} & \\text{C} & \\text{D} \\\\\n",
    "\\hline\n",
    "\\text{C} & 8,8 & 0,10 \\\\\n",
    "\\text{D} & 10,0 & 5,5 \\\\\n",
    "\\end{array}\n",
    "$\n",
    "\n",
    "If we expand the first two equations we get:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\text{} \\quad & u_1(C,C)s_2^C + u_1(C,D)s_2^D + r_1^C = U_1 \\\\\n",
    "\\text{} \\quad & u_1(D,C)s_2^C + u_1(D,D)s_2^D + r_1^D = U_1 \\\\\n",
    "\\text{} \\quad & u_2(C,C)s_1^C + u_2(D,C)s_1^D + r_2^C = U_2 \\\\\n",
    "\\text{} \\quad & u_2(C,D)s_1^C + u_2(D,D)s_1^D + r_2^D = U_2 \\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "And plugging in the values at equilibrium ($s_1^C=s_2^C=0$):\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\text{} \\quad & 8\\times 0 + 0\\times 1 + r_1^C = 5 \\\\\n",
    "\\text{} \\quad & 10\\times 0 + 5\\times 1 + r_1^D = 5 \\\\\n",
    "\\text{} \\quad & 8\\times 0 + 0\\times 1 + r_2^C = 5 \\\\\n",
    "\\text{} \\quad & 10\\times 0 + 5\\times 1 + r_2^D = 5 \\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "We can see that $r_1^C$ and $r_2^C$ are 5, as this is the amount you expect to lose by going with $C$, and the others are 0. \n",
    "\n",
    "#### The Lemke-Howson algorithm\n",
    "\n",
    "We know that at equilibrium the actions of agent 1 must either have 0 probability in $s_1$, or have a positive probability and be the best / equal best reponse to $s_2$ (if an action was not the best response to $s_2$, it would be better to set it's probability to 0 and use the other). The same is true of strategy $s_2$. This section of the equations above also make this clear:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\text{} \\quad & \\sum_{k} u_1(A_1^j,A_2^k)s_2^k + r_1^j = U_1 \\quad \\forall A_1^j \\\\\n",
    "\\text{} \\quad & \\sum_{j} u_2(A_1^j,A_2^k)s_1^j + r_2^k = U_2 \\quad \\forall A_2^k \\\\\n",
    "\\text{} \\quad & r_1^j\\cdot s_1^j = 0 \\\\\n",
    "\\text{} \\quad & r_2^k\\cdot s_2^k = 0 \\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "In fact, a nice way to rewrite the above might be as:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\text{} \\quad & \\sum_{k} u_1(A_1^j,A_2^k)s_2^k = U_1 \\quad \\forall A_1^j|s_1^j>0 \\\\\n",
    "\\text{} \\quad & \\sum_{j} u_2(A_1^j,A_2^k)s_1^j = U_2 \\quad \\forall A_2^k|s_2^k>0 \\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "So if we take the actions in equilibrium solution $s_1$ which have 0 probability and all the actions which are the best response to $s_2$, we should have the total list of all actions of the agent 1. The same is true of agent 2. So let's define for a solution a labelling function $L$ which lists all the 0-probability and best response actions. \n",
    "\n",
    "At equilibrium we will have: $L(s_1)\\cup L(s_2) = A_1\\cup A_2$\n",
    "\n",
    "Consider this two-player problem:\n",
    "\n",
    "$\n",
    "\\begin{array}{c|cc}\n",
    "\\text{} & \\text{A} & \\text{B} \\\\\n",
    "\\hline\n",
    "\\text{A} & 3,1 & 1,0 \\\\\n",
    "\\text{B} & 0,0 & 2,2 \\\\\n",
    "\\end{array}\n",
    "$\n",
    "\n",
    "Applying the approach from earlier we know that this game has an equilibrium at $s_1=\\frac{2}{3}$, and $s_2=\\frac{1}{4}$.\n",
    "\n",
    "\n",
    "We can represent the space of both players as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3f55ee81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "s1_A = np.linspace(0, 1, 100)\n",
    "s1_B = 1 - s1_A\n",
    "s2_A = np.linspace(0, 1, 100)\n",
    "s2_B = 1 - s2_A\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "# Player 1's plot\n",
    "ax1.plot(s1_A, s1_B)\n",
    "ax1.set_aspect('equal', adjustable='box')\n",
    "ax1.set_title('Player 1',fontsize=15)\n",
    "ax1.set_xlabel('A',fontsize=15)\n",
    "ax1.set_ylabel('B',fontsize=15)\n",
    "ax1.tick_params(labelsize=12)\n",
    "\n",
    "\n",
    "# Player 2's plot\n",
    "ax2.plot(s2_A, s2_B)\n",
    "ax2.set_aspect('equal', adjustable='box')\n",
    "ax2.set_title('Player 2',fontsize=15)\n",
    "ax2.set_xlabel('A',fontsize=15)\n",
    "ax2.set_ylabel('B',fontsize=15)\n",
    "ax2.tick_params(labelsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600c9394",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bcf66cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
