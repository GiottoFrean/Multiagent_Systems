{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ff9e94dd-d112-4310-b42c-fdc432a8b97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from graphviz import Digraph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e43818-0357-4bf4-b521-728aae058c50",
   "metadata": {},
   "source": [
    "# 6. Richer Representations: Beyond the Normal and Extensive Forms\n",
    "\n",
    "There are several reasons we want to explore other forms of game. Firstly, so far we have assumed a lot of finite variables. The number of decisions / time is finite, the players are finite, and the actions have been finite. We may want to consider what happens for infinite agents, or for games which are repeated forever. Secondly, so far we have assumed that agents share a knowledge of eachother's payoffs. This is very unrealistic! Thirdly, we would like to find more compact ways of describing games, for the sake of efficiency.\n",
    "\n",
    "## 6.1 Repeated games\n",
    "\n",
    "Consider a game like the prisoner's dilemma, in normal form, which is played multiple times. In the case that agents have no information about previous games the answer is pretty trivial. However, if agents can see what happened before then things become more complicated.\n",
    "\n",
    "### 6.1.1 Finitely repeated games\n",
    "\n",
    "With a finitely repeated game we simply need a bigger table in the normal form (or tree in the extensive form) to capture the strategies and payoffs for both players. We assume that agents don't know what eachother will play, but find out later. One simple answer is just to play the same strategy at each game level, which we call a *stationary strategy*. But in general, the action can depend on what was played before.\n",
    "\n",
    "All finitely repeated games can be represented as imperfect-information tree in extensive form. Player 1 does and action, then player 2 does an action (unknown by player 1), then both players see the result.\n",
    "\n",
    "### 6.1.2 Infinitely repeated games\n",
    "\n",
    "If a game is repeated infinitely we get an infinite tree of decisions. In order to quantify the reward of being in a state we can consider the average reward over all games, or a discounted reward of future games (i.e., the agent cares more about the present, or the games might end at some random point). \n",
    "\n",
    "In infinitely repeated games there are strategies other than the stationary ones. For instance we have Tit-for-Tat (TfT) in which players start by cooperating and then repeat whatever their opponent's strategy was.\n",
    "\n",
    "Ideally we want to be able to calculate the equilibirum strategies in infinitely repeated games. A good place to start is the **The Folk Theorem**, which states that an equilibrium exists for any average payoffs where the agents are each avoiding their worst outcome. These are equilibrium because players can threaten to cause the worst outcome of another in perpetuity if they deviate. Consider this game:\n",
    "\n",
    "$\n",
    "\\begin{array}{c|ccc}\n",
    "\\text{} & A & B \\\\\n",
    "\\hline\n",
    "\\text{A} & 4,4 & 1,5 \\\\\n",
    "\\text{B} & 5,1 & 0,0 \\\\\n",
    "\\end{array}\n",
    "$\n",
    "\n",
    "If we just analyse this as a one-off game we see there are two equilibria, at (A,B) and (B,A). But in the infinite case there is also the equilibria at (A,A). This is because both players can threaten to play B for the rest of time, if their opponent does. Remaining at A becomes an equilibrium strategy. We say (A,A) is *enforcable*.\n",
    "\n",
    "Note this fits for *any* set of enforable payoffs, not just the strategies that can be used. For instance, consider this game:\n",
    "\n",
    "$\n",
    "\\begin{array}{c|ccc}\n",
    "\\text{} & A & B \\\\\n",
    "\\hline\n",
    "\\text{A} & 0,0 & 0,1 \\\\\n",
    "\\text{B} & 1,0 & 0,0 \\\\\n",
    "\\end{array}\n",
    "$\n",
    "\n",
    "Say the agents are swapping between (A,B) and (B,A) each game. The average payoff is 0.5 for each. The row player can enforce this system by threatening to play B forever onwards if the column player deviates, and likewise the column player can threaten to play A forever if the row player deviates.\n",
    "\n",
    "While this is useful, it is very broad. For instance, if the strategy is to play (A,B) 99 times for every (B,A) this is still enforcible by the column player, thought it's unfair.\n",
    "\n",
    "### 6.1.3 \"Bounded rationality\": repeated games played by automata\n",
    "\n",
    "The big problem when dealing with repeated games is that there are many more options to choose from. This imposes a computational burden on the decision maker, which reduces their ability to be fully rational. We simply can't crunch out all the options. At the same time, people don't behave as we would expect from any rational model. Consider the finitely repeated prisoner's dilemma. When playing the last game it is obviously optimal to defect, there are no more games to worry about. But then if that's the case, and we expect our opponent to defect as well, then we should also defect one game earlier. And so it unwinds completely. But in reality people tend to cooperate at first instead. What other models might explain this fact?\n",
    "\n",
    "One early proposal was the idea of $\\epsilon$-equilibrium, which is where agents accept a given strategy so long as they are losing no more than $\\epsilon$ by sticking with it. I.e., the players can absorb some small loss. The nash equilibria is then just a special case at $\\epsilon=0$. Consider the Centipede game, where at each point the players if they cooperate alternate between receiving +2 and -1:\n",
    "\n",
    "$\n",
    "\\begin{array}{ccccccccc}\n",
    "\\text{A:} & 2 & 1 & 3 & 2 & 4 & 3 & 5\\\\\n",
    "\\text{B:} & 0 & 2 & 1 & 3 & 2 & 4 & 3 \\\\\n",
    "\\end{array}\n",
    "$\n",
    "\n",
    "In the fully rational case B will stop cooperating at the second-to-last step, as 4>3. Given that, A will stop at the third-to-last, and so on. Eventually the most rational thing for both players is to defect as soon as possible. But if we use $\\epsilon>1$, then neither player will mind losing at the last stage, and the chain goes right to the end.\n",
    "\n",
    "Another option, and one with a lot of success, is to restrict agent's behaviours to those which can be implemented by an automata. This fits nicely with the imperfect-information form tree, where we need to make a decision at each information-set. An example automata might be something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "631e59bd-a574-47ba-a9b7-09da2669ce6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 12.0.0 (20240803.0821)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"254pt\" height=\"84pt\"\n",
       " viewBox=\"0.00 0.00 254.25 83.54\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 79.54)\">\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-79.54 250.25,-79.54 250.25,4 -4,4\"/>\n",
       "<!-- Start -->\n",
       "<!-- C -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>C</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"118\" cy=\"-22.29\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"118\" y=\"-17.62\" font-family=\"Times,serif\" font-size=\"14.00\">C</text>\n",
       "</g>\n",
       "<!-- Start&#45;&gt;C -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>Start&#45;&gt;C</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M54.22,-22.29C62.12,-22.29 70.94,-22.29 79.43,-22.29\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"79.14,-25.79 89.14,-22.29 79.14,-18.79 79.14,-25.79\"/>\n",
       "</g>\n",
       "<!-- C&#45;&gt;C -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>C&#45;&gt;C</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M109.88,-39.7C108.36,-49.38 111.07,-58.29 118,-58.29 122.01,-58.29 124.6,-55.31 125.79,-50.93\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"129.28,-51.32 126.08,-41.22 122.28,-51.11 129.28,-51.32\"/>\n",
       "<text text-anchor=\"middle\" x=\"118\" y=\"-62.24\" font-family=\"Times,serif\" font-size=\"14.00\">C</text>\n",
       "</g>\n",
       "<!-- D -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>D</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"219.25\" cy=\"-22.29\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"219.25\" y=\"-17.62\" font-family=\"Times,serif\" font-size=\"14.00\">D</text>\n",
       "</g>\n",
       "<!-- C&#45;&gt;D -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>C&#45;&gt;D</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M145.34,-22.29C156.1,-22.29 168.76,-22.29 180.49,-22.29\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"180.28,-25.79 190.28,-22.29 180.28,-18.79 180.28,-25.79\"/>\n",
       "<text text-anchor=\"middle\" x=\"168.62\" y=\"-26.24\" font-family=\"Times,serif\" font-size=\"14.00\">D</text>\n",
       "</g>\n",
       "<!-- D&#45;&gt;C -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>D&#45;&gt;C</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M198.36,-10.35C191.04,-6.59 182.52,-2.94 174.25,-1.04 165.3,1 155.88,-0.96 147.39,-4.39\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"146.08,-1.14 138.62,-8.66 149.14,-7.43 146.08,-1.14\"/>\n",
       "<text text-anchor=\"middle\" x=\"168.62\" y=\"-5.24\" font-family=\"Times,serif\" font-size=\"14.00\">C</text>\n",
       "</g>\n",
       "<!-- D&#45;&gt;D -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>D&#45;&gt;D</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M210.21,-39.7C208.52,-49.38 211.54,-58.29 219.25,-58.29 223.71,-58.29 226.6,-55.31 227.91,-50.93\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"231.4,-51.33 228.24,-41.22 224.41,-51.09 231.4,-51.33\"/>\n",
       "<text text-anchor=\"middle\" x=\"219.25\" y=\"-62.24\" font-family=\"Times,serif\" font-size=\"14.00\">D</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x70314b0cd0d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "graph1 = Digraph()\n",
    "graph1.attr(rankdir='LR')\n",
    "graph1.node('Start', '', style='invis')\n",
    "graph1.node('C', 'C')\n",
    "graph1.node('D', 'D')\n",
    "graph1.edge('Start', 'C', '', color=\"black\")\n",
    "graph1.edge('C', 'C', 'C', color=\"black\")\n",
    "graph1.edge('C', 'D', 'D', color=\"black\")\n",
    "graph1.edge('D', 'C', 'C', color=\"black\")\n",
    "graph1.edge('D', 'D', 'D', color=\"black\")\n",
    "display(graph1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d3daee-cc1a-41ac-9345-b75fa21da225",
   "metadata": {},
   "source": [
    "This is a representation of the classic Tit-for-Tat strategy. An automata is just a specification of a list of states, an action to take each state, and a transition function for every action taken (including other player's). We can say that both players will decide which automata to use before the game, and put a limit on the size of the automata to constrain rationality. In order to do backwards-induction on a game with $k$ iterations you need $k$ states."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
