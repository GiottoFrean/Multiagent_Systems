<h1 id="multiagent-systems">Multiagent Systems</h1>
<p>My notes for the book Multiagent Systems by Yoav Shoham and Kevin
Leyton-Brown.</p>
<p>This repository contains a collection of exploratory notebooks
covering the foundations of multiagent systems. The material progresses
from basic coordination problems through game theory, learning, and
mechanism design.</p>
<p>Multiagent systems are everywhere: autonomous vehicles coordinating
traffic, distributed sensors aggregating information, trading algorithms
in financial markets, robots collaborating on tasks, and humans
negotiating agreements. Understanding how independent agents can
coordinate, compete, and coexist is fundamental to modern AI and
distributed systems.</p>
<p>The notebooks are organized into 10 major topics, each building on
previous concepts:</p>
<hr />
<h2 id="distributed-constraint-satisfaction"><a
href="1%20Distributed%20Constraint%20Satisfaction/">1. Distributed
Constraint Satisfaction</a></h2>
<p>How can independent agents coordinate to satisfy constraints without
a central controller? Uses graph coloring as the running example (e.g.,
cell towers selecting frequencies). Covers domain-pruning algorithms,
hyper-resolution, heuristic search, and the asynchronous backtracking
algorithm.</p>
<hr />
<h2 id="distributed-optimization"><a
href="2%20Distributed%20Optimization/">2. Distributed
Optimization</a></h2>
<p>Extends constraint satisfaction to optimization - finding the
<em>best</em> solution, not just any valid one. Covers dynamic
programming for path-finding, MDPs for stochastic environments, linear
programming, competitive equilibrium, and auctions.</p>
<hr />
<h2
id="introduction-to-noncooperative-game-theory---games-in-normal-form"><a
href="3%20Introduction%20to%20Noncooperative%20Game%20Theory%20-%20Games%20in%20Normal%20Form/">3.
Introduction to Noncooperative Game Theory - Games in Normal
Form</a></h2>
<p>Introduces game theory foundations: utility theory, normal-form
games, classic games (Prisoner’s Dilemma, Battle of the Sexes), Pareto
optimality, and Nash equilibrium. Shows that rational self-interested
behavior can lead to suboptimal outcomes.</p>
<hr />
<h2 id="computing-solution-concepts-for-normal-form-games"><a
href="4%20Computing%20solution%20concepts%20for%20Normal-Form%20games/">4.
Computing Solution Concepts for Normal-Form Games</a></h2>
<p>Unfortunately, computing Nash equilibria is computationally hard
(PPAD-complete). Covers algorithms for specific game classes: linear
programming for zero-sum games, support enumeration, Lemke-Howson
algorithm, dominated strategy elimination, and correlated
equilibria.</p>
<hr />
<h2 id="games-with-sequential-actions"><a
href="5%20Games%20with%20Sequential%20Actions/">5. Games with Sequential
Actions</a></h2>
<p>Moves beyond simultaneous-move games to sequential decision-making.
Covers perfect-information extensive-form games, backward induction,
subgame-perfect equilibrium, imperfect information with information
sets, and the sequence form for computational efficiency.</p>
<hr />
<h2
id="richer-representations---beyond-the-normal-and-extensive-forms"><a
href="6%20Richer%20Representations%20-%20Beyond%20the%20Normal%20and%20Extensive%20Forms/">6.
Richer Representations - Beyond the Normal and Extensive Forms</a></h2>
<p>Extends basic game models to capture more complex scenarios: repeated
games and the folk theorem, finite automata strategies, stochastic
games, Bayesian games with private information, congestion games, and
compact representations (graphical games).</p>
<hr />
<h2 id="learning-and-teaching"><a
href="7%20Learning%20and%20Teaching/">7. Learning and Teaching</a></h2>
<p>Learning in multiagent systems is fundamentally different from
single-agent learning because the environment changes as other agents
adapt. Covers fictitious play, rational learning, reinforcement
learning, no-regret learning, and evolutionary dynamics.</p>
<hr />
<h2 id="communication"><a href="8%20Communication/">8.
Communication</a></h2>
<p>When can agents benefit from communication? Covers cheap talk
(costless but potentially uninformative), signaling games (costly
signals that credibly reveal information), and speech-act theory
(commitments and revelation).</p>
<hr />
<h2 id="aggregating-preferences-social-choice"><a
href="9%20Aggregating%20preferences%2C%20social%20choice/">9.
Aggregating Preferences, Social Choice</a></h2>
<p>How do we aggregate individual preferences into collective decisions?
Covers voting systems, Arrow’s impossibility theorem, Condorcet winners,
and the fundamental tension between different desirable properties.</p>
<hr />
<h2 id="protocols-for-strategic-agents---mechanism-design"><a
href="10%20Protocols%20for%20Strategic%20Agents%20-%20Mechanism%20Design/">10.
Protocols for Strategic Agents - Mechanism Design</a></h2>
<p>Inverts game theory: instead of analyzing existing games, design new
ones to achieve desired outcomes. Covers the revelation principle,
Gibbard-Satterthwaite impossibility, Vickrey auctions, and VCG
mechanisms.</p>
<hr />
<h2 id="images">Images</h2>
<p>All visualizations from the notebooks have been extracted to the <a
href="images/"><code>images/</code></a> folder, organized by topic. The
extraction script <a
href="extract_notebook_images.py"><code>extract_notebook_images.py</code></a>
can regenerate these if needed.</p>
<hr />
<h2 id="structure">Structure</h2>
<p>Each numbered folder contains: - A <code>README.md</code> with
detailed descriptions of the notebooks - Jupyter notebooks
(<code>.ipynb</code> files) with implementations and examples - Heavy
use of NetworkX, matplotlib, and numpy for visualizations</p>
<p>The notebooks are designed to be self-contained and can be explored
in any order, though the numbering suggests a logical progression.</p>
